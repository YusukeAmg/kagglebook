{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train.target\n",
    "test_x = pd.read_csv('../input/sample-data/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   age                 10000 non-null  int64  \n",
      " 1   sex                 10000 non-null  int64  \n",
      " 2   height              10000 non-null  float64\n",
      " 3   weight              10000 non-null  float64\n",
      " 4   product             10000 non-null  int64  \n",
      " 5   amount              10000 non-null  int64  \n",
      " 6   medical_info_a1     10000 non-null  int64  \n",
      " 7   medical_info_a2     10000 non-null  int64  \n",
      " 8   medical_info_a3     10000 non-null  int64  \n",
      " 9   medical_info_b1     10000 non-null  int64  \n",
      " 10  medical_info_b2     10000 non-null  int64  \n",
      " 11  medical_info_b3     10000 non-null  int64  \n",
      " 12  medical_info_c1     7030 non-null   float64\n",
      " 13  medical_info_c2     1998 non-null   float64\n",
      " 14  medical_keyword_1   10000 non-null  int64  \n",
      " 15  medical_keyword_2   10000 non-null  int64  \n",
      " 16  medical_keyword_3   10000 non-null  int64  \n",
      " 17  medical_keyword_4   10000 non-null  int64  \n",
      " 18  medical_keyword_5   10000 non-null  int64  \n",
      " 19  medical_keyword_6   10000 non-null  int64  \n",
      " 20  medical_keyword_7   10000 non-null  int64  \n",
      " 21  medical_keyword_8   10000 non-null  int64  \n",
      " 22  medical_keyword_9   10000 non-null  int64  \n",
      " 23  medical_keyword_10  10000 non-null  int64  \n",
      " 24  year                10000 non-null  int64  \n",
      " 25  month               10000 non-null  int64  \n",
      " 26  day                 10000 non-null  int64  \n",
      " 27  yearmonth           10000 non-null  int64  \n",
      "dtypes: float64(4), int64(24)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "train_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, ca_idx = list(kf.split(train_x))[0]\n",
    "\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[tr_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[tr_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "dtest = xgb.DMatrix(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "num_round = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:44:53] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.12853\teval-error:0.12853\n",
      "[1]\ttrain-error:0.11533\teval-error:0.11533\n",
      "[2]\ttrain-error:0.10933\teval-error:0.10933\n",
      "[3]\ttrain-error:0.10533\teval-error:0.10533\n",
      "[4]\ttrain-error:0.09693\teval-error:0.09693\n",
      "[5]\ttrain-error:0.09467\teval-error:0.09467\n",
      "[6]\ttrain-error:0.08733\teval-error:0.08733\n",
      "[7]\ttrain-error:0.08493\teval-error:0.08493\n",
      "[8]\ttrain-error:0.07813\teval-error:0.07813\n",
      "[9]\ttrain-error:0.07373\teval-error:0.07373\n",
      "[10]\ttrain-error:0.06867\teval-error:0.06867\n",
      "[11]\ttrain-error:0.06493\teval-error:0.06493\n",
      "[12]\ttrain-error:0.06227\teval-error:0.06227\n",
      "[13]\ttrain-error:0.06053\teval-error:0.06053\n",
      "[14]\ttrain-error:0.05680\teval-error:0.05680\n",
      "[15]\ttrain-error:0.05040\teval-error:0.05040\n",
      "[16]\ttrain-error:0.04920\teval-error:0.04920\n",
      "[17]\ttrain-error:0.04640\teval-error:0.04640\n",
      "[18]\ttrain-error:0.04427\teval-error:0.04427\n",
      "[19]\ttrain-error:0.04347\teval-error:0.04347\n",
      "[20]\ttrain-error:0.03867\teval-error:0.03867\n",
      "[21]\ttrain-error:0.03653\teval-error:0.03653\n",
      "[22]\ttrain-error:0.03493\teval-error:0.03493\n",
      "[23]\ttrain-error:0.03373\teval-error:0.03373\n",
      "[24]\ttrain-error:0.03253\teval-error:0.03253\n",
      "[25]\ttrain-error:0.03120\teval-error:0.03120\n",
      "[26]\ttrain-error:0.02880\teval-error:0.02880\n",
      "[27]\ttrain-error:0.02773\teval-error:0.02773\n",
      "[28]\ttrain-error:0.02573\teval-error:0.02573\n",
      "[29]\ttrain-error:0.02320\teval-error:0.02320\n",
      "[30]\ttrain-error:0.02293\teval-error:0.02293\n",
      "[31]\ttrain-error:0.02067\teval-error:0.02067\n",
      "[32]\ttrain-error:0.01987\teval-error:0.01987\n",
      "[33]\ttrain-error:0.01973\teval-error:0.01973\n",
      "[34]\ttrain-error:0.01693\teval-error:0.01693\n",
      "[35]\ttrain-error:0.01733\teval-error:0.01733\n",
      "[36]\ttrain-error:0.01627\teval-error:0.01627\n",
      "[37]\ttrain-error:0.01520\teval-error:0.01520\n",
      "[38]\ttrain-error:0.01480\teval-error:0.01480\n",
      "[39]\ttrain-error:0.01453\teval-error:0.01453\n",
      "[40]\ttrain-error:0.01333\teval-error:0.01333\n",
      "[41]\ttrain-error:0.01253\teval-error:0.01253\n",
      "[42]\ttrain-error:0.01253\teval-error:0.01253\n",
      "[43]\ttrain-error:0.01147\teval-error:0.01147\n",
      "[44]\ttrain-error:0.01080\teval-error:0.01080\n",
      "[45]\ttrain-error:0.01093\teval-error:0.01093\n",
      "[46]\ttrain-error:0.01000\teval-error:0.01000\n",
      "[47]\ttrain-error:0.01027\teval-error:0.01027\n",
      "[48]\ttrain-error:0.00920\teval-error:0.00920\n",
      "[49]\ttrain-error:0.00947\teval-error:0.00947\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=num_round,\n",
    "    evals=watchlist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss:0.0695\n"
     ]
    }
   ],
   "source": [
    "va_pred = model.predict(dvalid)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss:{score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2064009 , 0.02400707, 0.00388634, ..., 0.83468455, 0.00239013,\n",
       "       0.22417206], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(dtest)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:37] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.54088\teval-logloss:0.54088\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-logloss:0.45269\teval-logloss:0.45269\n",
      "[2]\ttrain-logloss:0.39482\teval-logloss:0.39482\n",
      "[3]\ttrain-logloss:0.35198\teval-logloss:0.35198\n",
      "[4]\ttrain-logloss:0.32021\teval-logloss:0.32021\n",
      "[5]\ttrain-logloss:0.29673\teval-logloss:0.29673\n",
      "[6]\ttrain-logloss:0.27610\teval-logloss:0.27610\n",
      "[7]\ttrain-logloss:0.25886\teval-logloss:0.25886\n",
      "[8]\ttrain-logloss:0.24363\teval-logloss:0.24363\n",
      "[9]\ttrain-logloss:0.23153\teval-logloss:0.23153\n",
      "[10]\ttrain-logloss:0.22016\teval-logloss:0.22016\n",
      "[11]\ttrain-logloss:0.20963\teval-logloss:0.20963\n",
      "[12]\ttrain-logloss:0.19951\teval-logloss:0.19951\n",
      "[13]\ttrain-logloss:0.19324\teval-logloss:0.19324\n",
      "[14]\ttrain-logloss:0.18547\teval-logloss:0.18547\n",
      "[15]\ttrain-logloss:0.17474\teval-logloss:0.17474\n",
      "[16]\ttrain-logloss:0.16900\teval-logloss:0.16900\n",
      "[17]\ttrain-logloss:0.16323\teval-logloss:0.16323\n",
      "[18]\ttrain-logloss:0.15950\teval-logloss:0.15950\n",
      "[19]\ttrain-logloss:0.15637\teval-logloss:0.15637\n",
      "[20]\ttrain-logloss:0.14722\teval-logloss:0.14722\n",
      "[21]\ttrain-logloss:0.14290\teval-logloss:0.14290\n",
      "[22]\ttrain-logloss:0.13782\teval-logloss:0.13782\n",
      "[23]\ttrain-logloss:0.13362\teval-logloss:0.13362\n",
      "[24]\ttrain-logloss:0.13047\teval-logloss:0.13047\n",
      "[25]\ttrain-logloss:0.12654\teval-logloss:0.12654\n",
      "[26]\ttrain-logloss:0.12268\teval-logloss:0.12268\n",
      "[27]\ttrain-logloss:0.11966\teval-logloss:0.11966\n",
      "[28]\ttrain-logloss:0.11506\teval-logloss:0.11506\n",
      "[29]\ttrain-logloss:0.11027\teval-logloss:0.11027\n",
      "[30]\ttrain-logloss:0.10827\teval-logloss:0.10827\n",
      "[31]\ttrain-logloss:0.10262\teval-logloss:0.10262\n",
      "[32]\ttrain-logloss:0.10061\teval-logloss:0.10061\n",
      "[33]\ttrain-logloss:0.09913\teval-logloss:0.09913\n",
      "[34]\ttrain-logloss:0.09582\teval-logloss:0.09582\n",
      "[35]\ttrain-logloss:0.09378\teval-logloss:0.09378\n",
      "[36]\ttrain-logloss:0.09243\teval-logloss:0.09243\n",
      "[37]\ttrain-logloss:0.08952\teval-logloss:0.08952\n",
      "[38]\ttrain-logloss:0.08732\teval-logloss:0.08732\n",
      "[39]\ttrain-logloss:0.08576\teval-logloss:0.08576\n",
      "[40]\ttrain-logloss:0.08340\teval-logloss:0.08340\n",
      "[41]\ttrain-logloss:0.08125\teval-logloss:0.08125\n",
      "[42]\ttrain-logloss:0.08027\teval-logloss:0.08027\n",
      "[43]\ttrain-logloss:0.07829\teval-logloss:0.07829\n",
      "[44]\ttrain-logloss:0.07616\teval-logloss:0.07616\n",
      "[45]\ttrain-logloss:0.07522\teval-logloss:0.07522\n",
      "[46]\ttrain-logloss:0.07313\teval-logloss:0.07313\n",
      "[47]\ttrain-logloss:0.07198\teval-logloss:0.07198\n",
      "[48]\ttrain-logloss:0.07025\teval-logloss:0.07025\n",
      "[49]\ttrain-logloss:0.06947\teval-logloss:0.06947\n",
      "[50]\ttrain-logloss:0.06725\teval-logloss:0.06725\n",
      "[51]\ttrain-logloss:0.06608\teval-logloss:0.06608\n",
      "[52]\ttrain-logloss:0.06474\teval-logloss:0.06474\n",
      "[53]\ttrain-logloss:0.06343\teval-logloss:0.06343\n",
      "[54]\ttrain-logloss:0.06259\teval-logloss:0.06259\n",
      "[55]\ttrain-logloss:0.06163\teval-logloss:0.06163\n",
      "[56]\ttrain-logloss:0.06056\teval-logloss:0.06056\n",
      "[57]\ttrain-logloss:0.05859\teval-logloss:0.05859\n",
      "[58]\ttrain-logloss:0.05796\teval-logloss:0.05796\n",
      "[59]\ttrain-logloss:0.05692\teval-logloss:0.05692\n",
      "[60]\ttrain-logloss:0.05564\teval-logloss:0.05564\n",
      "[61]\ttrain-logloss:0.05500\teval-logloss:0.05500\n",
      "[62]\ttrain-logloss:0.05393\teval-logloss:0.05393\n",
      "[63]\ttrain-logloss:0.05339\teval-logloss:0.05339\n",
      "[64]\ttrain-logloss:0.05252\teval-logloss:0.05252\n",
      "[65]\ttrain-logloss:0.05096\teval-logloss:0.05096\n",
      "[66]\ttrain-logloss:0.05004\teval-logloss:0.05004\n",
      "[67]\ttrain-logloss:0.04909\teval-logloss:0.04909\n",
      "[68]\ttrain-logloss:0.04820\teval-logloss:0.04820\n",
      "[69]\ttrain-logloss:0.04725\teval-logloss:0.04725\n",
      "[70]\ttrain-logloss:0.04671\teval-logloss:0.04671\n",
      "[71]\ttrain-logloss:0.04575\teval-logloss:0.04575\n",
      "[72]\ttrain-logloss:0.04463\teval-logloss:0.04463\n",
      "[73]\ttrain-logloss:0.04405\teval-logloss:0.04405\n",
      "[74]\ttrain-logloss:0.04301\teval-logloss:0.04301\n",
      "[75]\ttrain-logloss:0.04262\teval-logloss:0.04262\n",
      "[76]\ttrain-logloss:0.04219\teval-logloss:0.04219\n",
      "[77]\ttrain-logloss:0.04157\teval-logloss:0.04157\n",
      "[78]\ttrain-logloss:0.04077\teval-logloss:0.04077\n",
      "[79]\ttrain-logloss:0.04002\teval-logloss:0.04002\n",
      "[80]\ttrain-logloss:0.03972\teval-logloss:0.03972\n",
      "[81]\ttrain-logloss:0.03874\teval-logloss:0.03874\n",
      "[82]\ttrain-logloss:0.03837\teval-logloss:0.03837\n",
      "[83]\ttrain-logloss:0.03807\teval-logloss:0.03807\n",
      "[84]\ttrain-logloss:0.03737\teval-logloss:0.03737\n",
      "[85]\ttrain-logloss:0.03669\teval-logloss:0.03669\n",
      "[86]\ttrain-logloss:0.03576\teval-logloss:0.03576\n",
      "[87]\ttrain-logloss:0.03553\teval-logloss:0.03553\n",
      "[88]\ttrain-logloss:0.03480\teval-logloss:0.03480\n",
      "[89]\ttrain-logloss:0.03425\teval-logloss:0.03425\n",
      "[90]\ttrain-logloss:0.03402\teval-logloss:0.03402\n",
      "[91]\ttrain-logloss:0.03342\teval-logloss:0.03342\n",
      "[92]\ttrain-logloss:0.03248\teval-logloss:0.03248\n",
      "[93]\ttrain-logloss:0.03195\teval-logloss:0.03195\n",
      "[94]\ttrain-logloss:0.03149\teval-logloss:0.03149\n",
      "[95]\ttrain-logloss:0.03062\teval-logloss:0.03062\n",
      "[96]\ttrain-logloss:0.03038\teval-logloss:0.03038\n",
      "[97]\ttrain-logloss:0.02992\teval-logloss:0.02992\n",
      "[98]\ttrain-logloss:0.02919\teval-logloss:0.02919\n",
      "[99]\ttrain-logloss:0.02860\teval-logloss:0.02860\n",
      "[100]\ttrain-logloss:0.02831\teval-logloss:0.02831\n",
      "[101]\ttrain-logloss:0.02762\teval-logloss:0.02762\n",
      "[102]\ttrain-logloss:0.02715\teval-logloss:0.02715\n",
      "[103]\ttrain-logloss:0.02699\teval-logloss:0.02699\n",
      "[104]\ttrain-logloss:0.02639\teval-logloss:0.02639\n",
      "[105]\ttrain-logloss:0.02593\teval-logloss:0.02593\n",
      "[106]\ttrain-logloss:0.02567\teval-logloss:0.02567\n",
      "[107]\ttrain-logloss:0.02511\teval-logloss:0.02511\n",
      "[108]\ttrain-logloss:0.02480\teval-logloss:0.02480\n",
      "[109]\ttrain-logloss:0.02445\teval-logloss:0.02445\n",
      "[110]\ttrain-logloss:0.02396\teval-logloss:0.02396\n",
      "[111]\ttrain-logloss:0.02365\teval-logloss:0.02365\n",
      "[112]\ttrain-logloss:0.02336\teval-logloss:0.02336\n",
      "[113]\ttrain-logloss:0.02317\teval-logloss:0.02317\n",
      "[114]\ttrain-logloss:0.02301\teval-logloss:0.02301\n",
      "[115]\ttrain-logloss:0.02265\teval-logloss:0.02265\n",
      "[116]\ttrain-logloss:0.02227\teval-logloss:0.02227\n",
      "[117]\ttrain-logloss:0.02193\teval-logloss:0.02193\n",
      "[118]\ttrain-logloss:0.02179\teval-logloss:0.02179\n",
      "[119]\ttrain-logloss:0.02148\teval-logloss:0.02148\n",
      "[120]\ttrain-logloss:0.02104\teval-logloss:0.02104\n",
      "[121]\ttrain-logloss:0.02085\teval-logloss:0.02085\n",
      "[122]\ttrain-logloss:0.02060\teval-logloss:0.02060\n",
      "[123]\ttrain-logloss:0.02017\teval-logloss:0.02017\n",
      "[124]\ttrain-logloss:0.01994\teval-logloss:0.01994\n",
      "[125]\ttrain-logloss:0.01971\teval-logloss:0.01971\n",
      "[126]\ttrain-logloss:0.01953\teval-logloss:0.01953\n",
      "[127]\ttrain-logloss:0.01946\teval-logloss:0.01946\n",
      "[128]\ttrain-logloss:0.01897\teval-logloss:0.01897\n",
      "[129]\ttrain-logloss:0.01875\teval-logloss:0.01875\n",
      "[130]\ttrain-logloss:0.01851\teval-logloss:0.01851\n",
      "[131]\ttrain-logloss:0.01832\teval-logloss:0.01832\n",
      "[132]\ttrain-logloss:0.01792\teval-logloss:0.01792\n",
      "[133]\ttrain-logloss:0.01777\teval-logloss:0.01777\n",
      "[134]\ttrain-logloss:0.01744\teval-logloss:0.01744\n",
      "[135]\ttrain-logloss:0.01730\teval-logloss:0.01730\n",
      "[136]\ttrain-logloss:0.01698\teval-logloss:0.01698\n",
      "[137]\ttrain-logloss:0.01668\teval-logloss:0.01668\n",
      "[138]\ttrain-logloss:0.01655\teval-logloss:0.01655\n",
      "[139]\ttrain-logloss:0.01639\teval-logloss:0.01639\n",
      "[140]\ttrain-logloss:0.01613\teval-logloss:0.01613\n",
      "[141]\ttrain-logloss:0.01605\teval-logloss:0.01605\n",
      "[142]\ttrain-logloss:0.01572\teval-logloss:0.01572\n",
      "[143]\ttrain-logloss:0.01563\teval-logloss:0.01563\n",
      "[144]\ttrain-logloss:0.01539\teval-logloss:0.01539\n",
      "[145]\ttrain-logloss:0.01512\teval-logloss:0.01512\n",
      "[146]\ttrain-logloss:0.01501\teval-logloss:0.01501\n",
      "[147]\ttrain-logloss:0.01488\teval-logloss:0.01488\n",
      "[148]\ttrain-logloss:0.01473\teval-logloss:0.01473\n",
      "[149]\ttrain-logloss:0.01464\teval-logloss:0.01464\n",
      "[150]\ttrain-logloss:0.01444\teval-logloss:0.01444\n",
      "[151]\ttrain-logloss:0.01423\teval-logloss:0.01423\n",
      "[152]\ttrain-logloss:0.01411\teval-logloss:0.01411\n",
      "[153]\ttrain-logloss:0.01406\teval-logloss:0.01406\n",
      "[154]\ttrain-logloss:0.01398\teval-logloss:0.01398\n",
      "[155]\ttrain-logloss:0.01374\teval-logloss:0.01374\n",
      "[156]\ttrain-logloss:0.01367\teval-logloss:0.01367\n",
      "[157]\ttrain-logloss:0.01351\teval-logloss:0.01351\n",
      "[158]\ttrain-logloss:0.01324\teval-logloss:0.01324\n",
      "[159]\ttrain-logloss:0.01317\teval-logloss:0.01317\n",
      "[160]\ttrain-logloss:0.01302\teval-logloss:0.01302\n",
      "[161]\ttrain-logloss:0.01295\teval-logloss:0.01295\n",
      "[162]\ttrain-logloss:0.01277\teval-logloss:0.01277\n",
      "[163]\ttrain-logloss:0.01263\teval-logloss:0.01263\n",
      "[164]\ttrain-logloss:0.01244\teval-logloss:0.01244\n",
      "[165]\ttrain-logloss:0.01231\teval-logloss:0.01231\n",
      "[166]\ttrain-logloss:0.01218\teval-logloss:0.01218\n",
      "[167]\ttrain-logloss:0.01211\teval-logloss:0.01211\n",
      "[168]\ttrain-logloss:0.01206\teval-logloss:0.01206\n",
      "[169]\ttrain-logloss:0.01193\teval-logloss:0.01193\n",
      "[170]\ttrain-logloss:0.01179\teval-logloss:0.01179\n",
      "[171]\ttrain-logloss:0.01165\teval-logloss:0.01165\n",
      "[172]\ttrain-logloss:0.01161\teval-logloss:0.01161\n",
      "[173]\ttrain-logloss:0.01149\teval-logloss:0.01149\n",
      "[174]\ttrain-logloss:0.01132\teval-logloss:0.01132\n",
      "[175]\ttrain-logloss:0.01116\teval-logloss:0.01116\n",
      "[176]\ttrain-logloss:0.01108\teval-logloss:0.01108\n",
      "[177]\ttrain-logloss:0.01092\teval-logloss:0.01092\n",
      "[178]\ttrain-logloss:0.01075\teval-logloss:0.01075\n",
      "[179]\ttrain-logloss:0.01067\teval-logloss:0.01067\n",
      "[180]\ttrain-logloss:0.01060\teval-logloss:0.01060\n",
      "[181]\ttrain-logloss:0.01053\teval-logloss:0.01053\n",
      "[182]\ttrain-logloss:0.01039\teval-logloss:0.01039\n",
      "[183]\ttrain-logloss:0.01031\teval-logloss:0.01031\n",
      "[184]\ttrain-logloss:0.01022\teval-logloss:0.01022\n",
      "[185]\ttrain-logloss:0.01013\teval-logloss:0.01013\n",
      "[186]\ttrain-logloss:0.01002\teval-logloss:0.01002\n",
      "[187]\ttrain-logloss:0.00990\teval-logloss:0.00990\n",
      "[188]\ttrain-logloss:0.00981\teval-logloss:0.00981\n",
      "[189]\ttrain-logloss:0.00975\teval-logloss:0.00975\n",
      "[190]\ttrain-logloss:0.00970\teval-logloss:0.00970\n",
      "[191]\ttrain-logloss:0.00964\teval-logloss:0.00964\n",
      "[192]\ttrain-logloss:0.00954\teval-logloss:0.00954\n",
      "[193]\ttrain-logloss:0.00950\teval-logloss:0.00950\n",
      "[194]\ttrain-logloss:0.00942\teval-logloss:0.00942\n",
      "[195]\ttrain-logloss:0.00931\teval-logloss:0.00931\n",
      "[196]\ttrain-logloss:0.00922\teval-logloss:0.00922\n",
      "[197]\ttrain-logloss:0.00911\teval-logloss:0.00911\n",
      "[198]\ttrain-logloss:0.00902\teval-logloss:0.00902\n",
      "[199]\ttrain-logloss:0.00895\teval-logloss:0.00895\n",
      "[200]\ttrain-logloss:0.00889\teval-logloss:0.00889\n",
      "[201]\ttrain-logloss:0.00882\teval-logloss:0.00882\n",
      "[202]\ttrain-logloss:0.00877\teval-logloss:0.00877\n",
      "[203]\ttrain-logloss:0.00873\teval-logloss:0.00873\n",
      "[204]\ttrain-logloss:0.00863\teval-logloss:0.00863\n",
      "[205]\ttrain-logloss:0.00857\teval-logloss:0.00857\n",
      "[206]\ttrain-logloss:0.00850\teval-logloss:0.00850\n",
      "[207]\ttrain-logloss:0.00844\teval-logloss:0.00844\n",
      "[208]\ttrain-logloss:0.00836\teval-logloss:0.00836\n",
      "[209]\ttrain-logloss:0.00831\teval-logloss:0.00831\n",
      "[210]\ttrain-logloss:0.00825\teval-logloss:0.00825\n",
      "[211]\ttrain-logloss:0.00818\teval-logloss:0.00818\n",
      "[212]\ttrain-logloss:0.00813\teval-logloss:0.00813\n",
      "[213]\ttrain-logloss:0.00807\teval-logloss:0.00807\n",
      "[214]\ttrain-logloss:0.00801\teval-logloss:0.00801\n",
      "[215]\ttrain-logloss:0.00792\teval-logloss:0.00792\n",
      "[216]\ttrain-logloss:0.00786\teval-logloss:0.00786\n",
      "[217]\ttrain-logloss:0.00777\teval-logloss:0.00777\n",
      "[218]\ttrain-logloss:0.00772\teval-logloss:0.00772\n",
      "[219]\ttrain-logloss:0.00766\teval-logloss:0.00766\n",
      "[220]\ttrain-logloss:0.00761\teval-logloss:0.00761\n",
      "[221]\ttrain-logloss:0.00753\teval-logloss:0.00753\n",
      "[222]\ttrain-logloss:0.00747\teval-logloss:0.00747\n",
      "[223]\ttrain-logloss:0.00742\teval-logloss:0.00742\n",
      "[224]\ttrain-logloss:0.00737\teval-logloss:0.00737\n",
      "[225]\ttrain-logloss:0.00735\teval-logloss:0.00735\n",
      "[226]\ttrain-logloss:0.00728\teval-logloss:0.00728\n",
      "[227]\ttrain-logloss:0.00724\teval-logloss:0.00724\n",
      "[228]\ttrain-logloss:0.00722\teval-logloss:0.00722\n",
      "[229]\ttrain-logloss:0.00717\teval-logloss:0.00717\n",
      "[230]\ttrain-logloss:0.00711\teval-logloss:0.00711\n",
      "[231]\ttrain-logloss:0.00709\teval-logloss:0.00709\n",
      "[232]\ttrain-logloss:0.00704\teval-logloss:0.00704\n",
      "[233]\ttrain-logloss:0.00701\teval-logloss:0.00701\n",
      "[234]\ttrain-logloss:0.00698\teval-logloss:0.00698\n",
      "[235]\ttrain-logloss:0.00692\teval-logloss:0.00692\n",
      "[236]\ttrain-logloss:0.00689\teval-logloss:0.00689\n",
      "[237]\ttrain-logloss:0.00685\teval-logloss:0.00685\n",
      "[238]\ttrain-logloss:0.00683\teval-logloss:0.00683\n",
      "[239]\ttrain-logloss:0.00675\teval-logloss:0.00675\n",
      "[240]\ttrain-logloss:0.00670\teval-logloss:0.00670\n",
      "[241]\ttrain-logloss:0.00663\teval-logloss:0.00663\n",
      "[242]\ttrain-logloss:0.00657\teval-logloss:0.00657\n",
      "[243]\ttrain-logloss:0.00654\teval-logloss:0.00654\n",
      "[244]\ttrain-logloss:0.00649\teval-logloss:0.00649\n",
      "[245]\ttrain-logloss:0.00642\teval-logloss:0.00642\n",
      "[246]\ttrain-logloss:0.00638\teval-logloss:0.00638\n",
      "[247]\ttrain-logloss:0.00636\teval-logloss:0.00636\n",
      "[248]\ttrain-logloss:0.00632\teval-logloss:0.00632\n",
      "[249]\ttrain-logloss:0.00628\teval-logloss:0.00628\n",
      "[250]\ttrain-logloss:0.00623\teval-logloss:0.00623\n",
      "[251]\ttrain-logloss:0.00619\teval-logloss:0.00619\n",
      "[252]\ttrain-logloss:0.00615\teval-logloss:0.00615\n",
      "[253]\ttrain-logloss:0.00611\teval-logloss:0.00611\n",
      "[254]\ttrain-logloss:0.00610\teval-logloss:0.00610\n",
      "[255]\ttrain-logloss:0.00605\teval-logloss:0.00605\n",
      "[256]\ttrain-logloss:0.00599\teval-logloss:0.00599\n",
      "[257]\ttrain-logloss:0.00597\teval-logloss:0.00597\n",
      "[258]\ttrain-logloss:0.00592\teval-logloss:0.00592\n",
      "[259]\ttrain-logloss:0.00588\teval-logloss:0.00588\n",
      "[260]\ttrain-logloss:0.00584\teval-logloss:0.00584\n",
      "[261]\ttrain-logloss:0.00580\teval-logloss:0.00580\n",
      "[262]\ttrain-logloss:0.00577\teval-logloss:0.00577\n",
      "[263]\ttrain-logloss:0.00575\teval-logloss:0.00575\n",
      "[264]\ttrain-logloss:0.00570\teval-logloss:0.00570\n",
      "[265]\ttrain-logloss:0.00567\teval-logloss:0.00567\n",
      "[266]\ttrain-logloss:0.00563\teval-logloss:0.00563\n",
      "[267]\ttrain-logloss:0.00559\teval-logloss:0.00559\n",
      "[268]\ttrain-logloss:0.00556\teval-logloss:0.00556\n",
      "[269]\ttrain-logloss:0.00552\teval-logloss:0.00552\n",
      "[270]\ttrain-logloss:0.00548\teval-logloss:0.00548\n",
      "[271]\ttrain-logloss:0.00545\teval-logloss:0.00545\n",
      "[272]\ttrain-logloss:0.00543\teval-logloss:0.00543\n",
      "[273]\ttrain-logloss:0.00540\teval-logloss:0.00540\n",
      "[274]\ttrain-logloss:0.00539\teval-logloss:0.00539\n",
      "[275]\ttrain-logloss:0.00537\teval-logloss:0.00537\n",
      "[276]\ttrain-logloss:0.00533\teval-logloss:0.00533\n",
      "[277]\ttrain-logloss:0.00531\teval-logloss:0.00531\n",
      "[278]\ttrain-logloss:0.00528\teval-logloss:0.00528\n",
      "[279]\ttrain-logloss:0.00523\teval-logloss:0.00523\n",
      "[280]\ttrain-logloss:0.00520\teval-logloss:0.00520\n",
      "[281]\ttrain-logloss:0.00516\teval-logloss:0.00516\n",
      "[282]\ttrain-logloss:0.00515\teval-logloss:0.00515\n",
      "[283]\ttrain-logloss:0.00512\teval-logloss:0.00512\n",
      "[284]\ttrain-logloss:0.00509\teval-logloss:0.00509\n",
      "[285]\ttrain-logloss:0.00507\teval-logloss:0.00507\n",
      "[286]\ttrain-logloss:0.00504\teval-logloss:0.00504\n",
      "[287]\ttrain-logloss:0.00502\teval-logloss:0.00502\n",
      "[288]\ttrain-logloss:0.00498\teval-logloss:0.00498\n",
      "[289]\ttrain-logloss:0.00495\teval-logloss:0.00495\n",
      "[290]\ttrain-logloss:0.00492\teval-logloss:0.00492\n",
      "[291]\ttrain-logloss:0.00489\teval-logloss:0.00489\n",
      "[292]\ttrain-logloss:0.00487\teval-logloss:0.00487\n",
      "[293]\ttrain-logloss:0.00485\teval-logloss:0.00485\n",
      "[294]\ttrain-logloss:0.00482\teval-logloss:0.00482\n",
      "[295]\ttrain-logloss:0.00479\teval-logloss:0.00479\n",
      "[296]\ttrain-logloss:0.00477\teval-logloss:0.00477\n",
      "[297]\ttrain-logloss:0.00473\teval-logloss:0.00473\n",
      "[298]\ttrain-logloss:0.00470\teval-logloss:0.00470\n",
      "[299]\ttrain-logloss:0.00468\teval-logloss:0.00468\n",
      "[300]\ttrain-logloss:0.00466\teval-logloss:0.00466\n",
      "[301]\ttrain-logloss:0.00464\teval-logloss:0.00464\n",
      "[302]\ttrain-logloss:0.00462\teval-logloss:0.00462\n",
      "[303]\ttrain-logloss:0.00459\teval-logloss:0.00459\n",
      "[304]\ttrain-logloss:0.00457\teval-logloss:0.00457\n",
      "[305]\ttrain-logloss:0.00454\teval-logloss:0.00454\n",
      "[306]\ttrain-logloss:0.00453\teval-logloss:0.00453\n",
      "[307]\ttrain-logloss:0.00450\teval-logloss:0.00450\n",
      "[308]\ttrain-logloss:0.00448\teval-logloss:0.00448\n",
      "[309]\ttrain-logloss:0.00446\teval-logloss:0.00446\n",
      "[310]\ttrain-logloss:0.00444\teval-logloss:0.00444\n",
      "[311]\ttrain-logloss:0.00441\teval-logloss:0.00441\n",
      "[312]\ttrain-logloss:0.00439\teval-logloss:0.00439\n",
      "[313]\ttrain-logloss:0.00437\teval-logloss:0.00437\n",
      "[314]\ttrain-logloss:0.00434\teval-logloss:0.00434\n",
      "[315]\ttrain-logloss:0.00433\teval-logloss:0.00433\n",
      "[316]\ttrain-logloss:0.00431\teval-logloss:0.00431\n",
      "[317]\ttrain-logloss:0.00429\teval-logloss:0.00429\n",
      "[318]\ttrain-logloss:0.00427\teval-logloss:0.00427\n",
      "[319]\ttrain-logloss:0.00425\teval-logloss:0.00425\n",
      "[320]\ttrain-logloss:0.00424\teval-logloss:0.00424\n",
      "[321]\ttrain-logloss:0.00422\teval-logloss:0.00422\n",
      "[322]\ttrain-logloss:0.00420\teval-logloss:0.00420\n",
      "[323]\ttrain-logloss:0.00419\teval-logloss:0.00419\n",
      "[324]\ttrain-logloss:0.00417\teval-logloss:0.00417\n",
      "[325]\ttrain-logloss:0.00415\teval-logloss:0.00415\n",
      "[326]\ttrain-logloss:0.00413\teval-logloss:0.00413\n",
      "[327]\ttrain-logloss:0.00412\teval-logloss:0.00412\n",
      "[328]\ttrain-logloss:0.00409\teval-logloss:0.00409\n",
      "[329]\ttrain-logloss:0.00408\teval-logloss:0.00408\n",
      "[330]\ttrain-logloss:0.00405\teval-logloss:0.00405\n",
      "[331]\ttrain-logloss:0.00403\teval-logloss:0.00403\n",
      "[332]\ttrain-logloss:0.00402\teval-logloss:0.00402\n",
      "[333]\ttrain-logloss:0.00401\teval-logloss:0.00401\n",
      "[334]\ttrain-logloss:0.00398\teval-logloss:0.00398\n",
      "[335]\ttrain-logloss:0.00396\teval-logloss:0.00396\n",
      "[336]\ttrain-logloss:0.00395\teval-logloss:0.00395\n",
      "[337]\ttrain-logloss:0.00393\teval-logloss:0.00393\n",
      "[338]\ttrain-logloss:0.00392\teval-logloss:0.00392\n",
      "[339]\ttrain-logloss:0.00390\teval-logloss:0.00390\n",
      "[340]\ttrain-logloss:0.00388\teval-logloss:0.00388\n",
      "[341]\ttrain-logloss:0.00386\teval-logloss:0.00386\n",
      "[342]\ttrain-logloss:0.00384\teval-logloss:0.00384\n",
      "[343]\ttrain-logloss:0.00382\teval-logloss:0.00382\n",
      "[344]\ttrain-logloss:0.00381\teval-logloss:0.00381\n",
      "[345]\ttrain-logloss:0.00379\teval-logloss:0.00379\n",
      "[346]\ttrain-logloss:0.00378\teval-logloss:0.00378\n",
      "[347]\ttrain-logloss:0.00376\teval-logloss:0.00376\n",
      "[348]\ttrain-logloss:0.00375\teval-logloss:0.00375\n",
      "[349]\ttrain-logloss:0.00374\teval-logloss:0.00374\n",
      "[350]\ttrain-logloss:0.00372\teval-logloss:0.00372\n",
      "[351]\ttrain-logloss:0.00371\teval-logloss:0.00371\n",
      "[352]\ttrain-logloss:0.00369\teval-logloss:0.00369\n",
      "[353]\ttrain-logloss:0.00367\teval-logloss:0.00367\n",
      "[354]\ttrain-logloss:0.00366\teval-logloss:0.00366\n",
      "[355]\ttrain-logloss:0.00365\teval-logloss:0.00365\n",
      "[356]\ttrain-logloss:0.00363\teval-logloss:0.00363\n",
      "[357]\ttrain-logloss:0.00362\teval-logloss:0.00362\n",
      "[358]\ttrain-logloss:0.00360\teval-logloss:0.00360\n",
      "[359]\ttrain-logloss:0.00359\teval-logloss:0.00359\n",
      "[360]\ttrain-logloss:0.00358\teval-logloss:0.00358\n",
      "[361]\ttrain-logloss:0.00357\teval-logloss:0.00357\n",
      "[362]\ttrain-logloss:0.00355\teval-logloss:0.00355\n",
      "[363]\ttrain-logloss:0.00353\teval-logloss:0.00353\n",
      "[364]\ttrain-logloss:0.00351\teval-logloss:0.00351\n",
      "[365]\ttrain-logloss:0.00351\teval-logloss:0.00351\n",
      "[366]\ttrain-logloss:0.00350\teval-logloss:0.00350\n",
      "[367]\ttrain-logloss:0.00348\teval-logloss:0.00348\n",
      "[368]\ttrain-logloss:0.00347\teval-logloss:0.00347\n",
      "[369]\ttrain-logloss:0.00346\teval-logloss:0.00346\n",
      "[370]\ttrain-logloss:0.00345\teval-logloss:0.00345\n",
      "[371]\ttrain-logloss:0.00343\teval-logloss:0.00343\n",
      "[372]\ttrain-logloss:0.00342\teval-logloss:0.00342\n",
      "[373]\ttrain-logloss:0.00340\teval-logloss:0.00340\n",
      "[374]\ttrain-logloss:0.00339\teval-logloss:0.00339\n",
      "[375]\ttrain-logloss:0.00338\teval-logloss:0.00338\n",
      "[376]\ttrain-logloss:0.00336\teval-logloss:0.00336\n",
      "[377]\ttrain-logloss:0.00335\teval-logloss:0.00335\n",
      "[378]\ttrain-logloss:0.00334\teval-logloss:0.00334\n",
      "[379]\ttrain-logloss:0.00333\teval-logloss:0.00333\n",
      "[380]\ttrain-logloss:0.00332\teval-logloss:0.00332\n",
      "[381]\ttrain-logloss:0.00331\teval-logloss:0.00331\n",
      "[382]\ttrain-logloss:0.00330\teval-logloss:0.00330\n",
      "[383]\ttrain-logloss:0.00329\teval-logloss:0.00329\n",
      "[384]\ttrain-logloss:0.00328\teval-logloss:0.00328\n",
      "[385]\ttrain-logloss:0.00327\teval-logloss:0.00327\n",
      "[386]\ttrain-logloss:0.00326\teval-logloss:0.00326\n",
      "[387]\ttrain-logloss:0.00325\teval-logloss:0.00325\n",
      "[388]\ttrain-logloss:0.00323\teval-logloss:0.00323\n",
      "[389]\ttrain-logloss:0.00323\teval-logloss:0.00323\n",
      "[390]\ttrain-logloss:0.00321\teval-logloss:0.00321\n",
      "[391]\ttrain-logloss:0.00320\teval-logloss:0.00320\n",
      "[392]\ttrain-logloss:0.00319\teval-logloss:0.00319\n",
      "[393]\ttrain-logloss:0.00318\teval-logloss:0.00318\n",
      "[394]\ttrain-logloss:0.00317\teval-logloss:0.00317\n",
      "[395]\ttrain-logloss:0.00315\teval-logloss:0.00315\n",
      "[396]\ttrain-logloss:0.00314\teval-logloss:0.00314\n",
      "[397]\ttrain-logloss:0.00313\teval-logloss:0.00313\n",
      "[398]\ttrain-logloss:0.00312\teval-logloss:0.00312\n",
      "[399]\ttrain-logloss:0.00311\teval-logloss:0.00311\n",
      "[400]\ttrain-logloss:0.00311\teval-logloss:0.00311\n",
      "[401]\ttrain-logloss:0.00310\teval-logloss:0.00310\n",
      "[402]\ttrain-logloss:0.00309\teval-logloss:0.00309\n",
      "[403]\ttrain-logloss:0.00307\teval-logloss:0.00307\n",
      "[404]\ttrain-logloss:0.00306\teval-logloss:0.00306\n",
      "[405]\ttrain-logloss:0.00306\teval-logloss:0.00306\n",
      "[406]\ttrain-logloss:0.00305\teval-logloss:0.00305\n",
      "[407]\ttrain-logloss:0.00304\teval-logloss:0.00304\n",
      "[408]\ttrain-logloss:0.00303\teval-logloss:0.00303\n",
      "[409]\ttrain-logloss:0.00302\teval-logloss:0.00302\n",
      "[410]\ttrain-logloss:0.00301\teval-logloss:0.00301\n",
      "[411]\ttrain-logloss:0.00300\teval-logloss:0.00300\n",
      "[412]\ttrain-logloss:0.00299\teval-logloss:0.00299\n",
      "[413]\ttrain-logloss:0.00298\teval-logloss:0.00298\n",
      "[414]\ttrain-logloss:0.00297\teval-logloss:0.00297\n",
      "[415]\ttrain-logloss:0.00297\teval-logloss:0.00297\n",
      "[416]\ttrain-logloss:0.00296\teval-logloss:0.00296\n",
      "[417]\ttrain-logloss:0.00295\teval-logloss:0.00295\n",
      "[418]\ttrain-logloss:0.00294\teval-logloss:0.00294\n",
      "[419]\ttrain-logloss:0.00294\teval-logloss:0.00294\n",
      "[420]\ttrain-logloss:0.00293\teval-logloss:0.00293\n",
      "[421]\ttrain-logloss:0.00292\teval-logloss:0.00292\n",
      "[422]\ttrain-logloss:0.00291\teval-logloss:0.00291\n",
      "[423]\ttrain-logloss:0.00290\teval-logloss:0.00290\n",
      "[424]\ttrain-logloss:0.00289\teval-logloss:0.00289\n",
      "[425]\ttrain-logloss:0.00289\teval-logloss:0.00289\n",
      "[426]\ttrain-logloss:0.00288\teval-logloss:0.00288\n",
      "[427]\ttrain-logloss:0.00286\teval-logloss:0.00286\n",
      "[428]\ttrain-logloss:0.00286\teval-logloss:0.00286\n",
      "[429]\ttrain-logloss:0.00285\teval-logloss:0.00285\n",
      "[430]\ttrain-logloss:0.00284\teval-logloss:0.00284\n",
      "[431]\ttrain-logloss:0.00283\teval-logloss:0.00283\n",
      "[432]\ttrain-logloss:0.00282\teval-logloss:0.00282\n",
      "[433]\ttrain-logloss:0.00282\teval-logloss:0.00282\n",
      "[434]\ttrain-logloss:0.00281\teval-logloss:0.00281\n",
      "[435]\ttrain-logloss:0.00280\teval-logloss:0.00280\n",
      "[436]\ttrain-logloss:0.00279\teval-logloss:0.00279\n",
      "[437]\ttrain-logloss:0.00278\teval-logloss:0.00278\n",
      "[438]\ttrain-logloss:0.00278\teval-logloss:0.00278\n",
      "[439]\ttrain-logloss:0.00277\teval-logloss:0.00277\n",
      "[440]\ttrain-logloss:0.00276\teval-logloss:0.00276\n",
      "[441]\ttrain-logloss:0.00276\teval-logloss:0.00276\n",
      "[442]\ttrain-logloss:0.00275\teval-logloss:0.00275\n",
      "[443]\ttrain-logloss:0.00275\teval-logloss:0.00275\n",
      "[444]\ttrain-logloss:0.00274\teval-logloss:0.00274\n",
      "[445]\ttrain-logloss:0.00273\teval-logloss:0.00273\n",
      "[446]\ttrain-logloss:0.00272\teval-logloss:0.00272\n",
      "[447]\ttrain-logloss:0.00271\teval-logloss:0.00271\n",
      "[448]\ttrain-logloss:0.00271\teval-logloss:0.00271\n",
      "[449]\ttrain-logloss:0.00270\teval-logloss:0.00270\n",
      "[450]\ttrain-logloss:0.00269\teval-logloss:0.00269\n",
      "[451]\ttrain-logloss:0.00268\teval-logloss:0.00268\n",
      "[452]\ttrain-logloss:0.00267\teval-logloss:0.00267\n",
      "[453]\ttrain-logloss:0.00266\teval-logloss:0.00266\n",
      "[454]\ttrain-logloss:0.00266\teval-logloss:0.00266\n",
      "[455]\ttrain-logloss:0.00265\teval-logloss:0.00265\n",
      "[456]\ttrain-logloss:0.00265\teval-logloss:0.00265\n",
      "[457]\ttrain-logloss:0.00264\teval-logloss:0.00264\n",
      "[458]\ttrain-logloss:0.00263\teval-logloss:0.00263\n",
      "[459]\ttrain-logloss:0.00262\teval-logloss:0.00262\n",
      "[460]\ttrain-logloss:0.00262\teval-logloss:0.00262\n",
      "[461]\ttrain-logloss:0.00261\teval-logloss:0.00261\n",
      "[462]\ttrain-logloss:0.00261\teval-logloss:0.00261\n",
      "[463]\ttrain-logloss:0.00260\teval-logloss:0.00260\n",
      "[464]\ttrain-logloss:0.00259\teval-logloss:0.00259\n",
      "[465]\ttrain-logloss:0.00259\teval-logloss:0.00259\n",
      "[466]\ttrain-logloss:0.00258\teval-logloss:0.00258\n",
      "[467]\ttrain-logloss:0.00257\teval-logloss:0.00257\n",
      "[468]\ttrain-logloss:0.00257\teval-logloss:0.00257\n",
      "[469]\ttrain-logloss:0.00256\teval-logloss:0.00256\n",
      "[470]\ttrain-logloss:0.00256\teval-logloss:0.00256\n",
      "[471]\ttrain-logloss:0.00255\teval-logloss:0.00255\n",
      "[472]\ttrain-logloss:0.00254\teval-logloss:0.00254\n",
      "[473]\ttrain-logloss:0.00253\teval-logloss:0.00253\n",
      "[474]\ttrain-logloss:0.00253\teval-logloss:0.00253\n",
      "[475]\ttrain-logloss:0.00252\teval-logloss:0.00252\n",
      "[476]\ttrain-logloss:0.00252\teval-logloss:0.00252\n",
      "[477]\ttrain-logloss:0.00251\teval-logloss:0.00251\n",
      "[478]\ttrain-logloss:0.00251\teval-logloss:0.00251\n",
      "[479]\ttrain-logloss:0.00250\teval-logloss:0.00250\n",
      "[480]\ttrain-logloss:0.00249\teval-logloss:0.00249\n",
      "[481]\ttrain-logloss:0.00249\teval-logloss:0.00249\n",
      "[482]\ttrain-logloss:0.00248\teval-logloss:0.00248\n",
      "[483]\ttrain-logloss:0.00248\teval-logloss:0.00248\n",
      "[484]\ttrain-logloss:0.00247\teval-logloss:0.00247\n",
      "[485]\ttrain-logloss:0.00247\teval-logloss:0.00247\n",
      "[486]\ttrain-logloss:0.00246\teval-logloss:0.00246\n",
      "[487]\ttrain-logloss:0.00245\teval-logloss:0.00245\n",
      "[488]\ttrain-logloss:0.00245\teval-logloss:0.00245\n",
      "[489]\ttrain-logloss:0.00244\teval-logloss:0.00244\n",
      "[490]\ttrain-logloss:0.00244\teval-logloss:0.00244\n",
      "[491]\ttrain-logloss:0.00243\teval-logloss:0.00243\n",
      "[492]\ttrain-logloss:0.00242\teval-logloss:0.00242\n",
      "[493]\ttrain-logloss:0.00242\teval-logloss:0.00242\n",
      "[494]\ttrain-logloss:0.00242\teval-logloss:0.00242\n",
      "[495]\ttrain-logloss:0.00241\teval-logloss:0.00241\n",
      "[496]\ttrain-logloss:0.00240\teval-logloss:0.00240\n",
      "[497]\ttrain-logloss:0.00240\teval-logloss:0.00240\n",
      "[498]\ttrain-logloss:0.00239\teval-logloss:0.00239\n",
      "[499]\ttrain-logloss:0.00238\teval-logloss:0.00238\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'binary:logistic', 'silent':1, 'random_state':71, 'eval_metric' :'logloss'}\n",
    "num_round = 500\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params=params, dtrain=dtrain, num_boost_round=num_round, evals=watchlist, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.19892955e-01 1.90523744e-04 2.04496814e-06 ... 9.75438714e-01\n",
      " 6.37821174e-08 5.99980317e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "print(pred)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
